{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DP-FT\n",
    "\n",
    "uncertain graph approach based on important nodes\n",
    "\n",
    "this method is incredibly time intensive. time sink is in computing the Similarity matrix\n",
    "\n",
    "We probably want to use t = 5, since thats the length of the random walk that we used in the other random walk based methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "\n",
    "import itertools\n",
    "\n",
    "import random\n",
    "from scipy.stats import dlaplace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we use the DD199 graph for testing\n",
    "import pandas as pd\n",
    "DD199 = nx.read_edgelist(\"Data/DD199/DD199.edges\", nodetype=int)\n",
    "\n",
    "BAG = nx.barabasi_albert_graph(20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_compute(G:nx.Graph, t:int):\n",
    "    ## 1: Initialize TransMatrix and SimMatrix where TransMatrix has size |V|x|V| and \n",
    "    starttime = time.time()\n",
    "    d = G.degree()\n",
    "    SimDict = {i:{j:1/d[i] if (i,j) in G.edges() else 0 for j in G.nodes()} for i in G.nodes()}\n",
    "    SimMatrix = pd.DataFrame(SimDict)   ## for the sake of my sanity we use pandas (ease of use)\n",
    "    TemMatrix = SimMatrix.copy()\n",
    "    HelperMatrix = TemMatrix.copy()\n",
    "    TransMatrix = SimMatrix.copy()      ## does not change from here\n",
    "    walksteps = 1\n",
    "    while walksteps < t:        ## 2: repeat 5: until walksteps >= t\n",
    "        ## 3: random walk calculate 2-step transistion prob vi to vi\n",
    "        ## 2-step transition probability is given by prob that the m+2th stop is j given that the mth stop is i\n",
    "        ## prob that i goes to k * prob k goes to j; sum of s[i][k]*s[k][j] for all  k\n",
    "        for i in G.nodes():\n",
    "            for j in G.nodes():     ## using pseudocode method, there is interference with the updating columns\n",
    "                ## df[\"col\"][row_indexer] = value Use `df.loc[row_indexer, \"col\"] = values` instead,\n",
    "                ##TemMatrix[i][j] = sum(HelperMatrix[i][:]*TransMatrix[:][j])\n",
    "                ## sum is over intersection of neighbors of vi and vj so:\n",
    "                vk = [ni for ni in G.neighbors(i) if ni in G.neighbors(j)]\n",
    "                TemMatrix.loc[j,i] = sum((HelperMatrix[i][:]*TransMatrix.T[j][:])[vk])\n",
    "        ## 4: Update SimMatrix\n",
    "        SimMatrix = SimMatrix + TemMatrix\n",
    "        HelperMatrix = TemMatrix.copy()\n",
    "        walksteps += 1\n",
    "    ## 6:\n",
    "    print(time.time()-starttime)\n",
    "    return SimMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_distance_compute(G:nx.Graph, t:int):\n",
    "    '''Compute the SimMatrix of the graph G for a random walk length of t\n",
    "    '''\n",
    "    ## sim[i][j] = pij + pij^2 + pij ^3 + ... + pij^t where pij^n is the probability to go from i to j in exactly n steps\n",
    "    ## we can compute this by computing powers of the transition matrix, (to get pij^n) and adding them\n",
    "    ##starttime = time.time()\n",
    "    d = dict(G.degree())\n",
    "    T = [[(1/d[i])*((i,j) in G.edges()) for i in G.nodes()] for j in G.nodes()]\n",
    "    T = np.array(T)\n",
    "\n",
    "    ## getting the transition matrix. We assume in doing this that the nodes are in a sensible order\n",
    "    helper = T.copy()\n",
    "    \n",
    "    SimMatrix = np.zeros((G.number_of_nodes(),G.number_of_nodes()))\n",
    "    for i in range(1,t+1):\n",
    "        ## helper = T^i\n",
    "        SimMatrix = np.add(SimMatrix,  helper) ## SimMatrix = sum of those\n",
    "        helper = np.matmul(helper,T)  ## helper = T^i+1\n",
    "        \n",
    "    ##print(time.time()-starttime)\n",
    "    return SimMatrix\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DP_FT(G:nx.Graph, epsilon = 1, t:int = 5, Rseed = None):\n",
    "    '''\n",
    "    Input: graph G, privacy budget epsilon, number of steps for random walk t (default 2 as in original paper)\n",
    "    Output: list of edges E_T\n",
    "    note: original paper uses epsilon in [0.5, 3] in steps of 0.5, they got good results for epsilon <= 1\n",
    "    '''\n",
    "    random.seed(Rseed)\n",
    "    ## 1: initialization of SimMatrix, M_force, E_T, and queue -> probably unnecessary in python\n",
    "    ##starttime = time.time()\n",
    "    \n",
    "    F = {i:{j:0 for j in G.nodes()} for i in G.nodes()}   ## something with a double index structure\n",
    "    E_T = []\n",
    "    queue = [] \n",
    "    V = list(G.nodes())     ## 2      ## list form so that we can sensibly modify it later\n",
    "    d = dict(G.degree())    ## 3    ## we call it d rather than S so that getting the degree of a node is more intuitive\n",
    "    SimMatrix = fast_distance_compute(G,t)   ## 4, 1 (initialization)\n",
    "    ## 5,6,7: for each node pair vi vj in G, NodeSim(i,j) = SimMatrix[i][j] -> just use SimMatrix[i,j]\n",
    "    candidates = {}         ## vi_candidates is used again later so we initialize it outside the loop\n",
    "    \n",
    "    ##print(\"Init: \",time.time() - starttime)\n",
    "    ##starttime = time.time()\n",
    "    \n",
    "    for vi in V:            ## 8, 16\n",
    "        candidates[vi] = [vv for vv in V if SimMatrix[vi][vv] != 0 and vi != vv] ## 9   ## seems like we prob want vi = vv excluded\n",
    "        ## 10,14: if vi_cand not empty then: -> not necc in python\n",
    "        for vv in candidates[vi]:    ## 11, 13\n",
    "            ##12: M_force[i][v] = F(i,v)    where F(a,b) = d(a) * d(b) * NodeSim(a,b)^n where NodeSim(i,j) = SimMatrix[i][j]\n",
    "            ##       we omit ^n because we use n = 1, as in experiments from orig. paper\n",
    "            F[vi][vv] = d[vi]*d[vv]*SimMatrix[vi][vv]   ## vertex indexing is the same as the vertices by construction\n",
    "\n",
    "    ## F = {vi: {vv: d[vi]*d[vv]*SimMatrix[vi][vv] for vv in V} for vi in V} ## might be faster\n",
    "    ## also do candidates = {vi:[vv for vv in V if SimMatrix[vi][vv] != 0 and vi!=vv] for vi in V}\n",
    "    \n",
    "    ## 16: // adding Laplacian noise to degree sequence S to get S_tilde -> modified in place, S is called d, for ease of use\n",
    "    if epsilon != 0:        ## 17, 22\n",
    "        for vi in d.keys(): ## 18, 21   ## d is node:degree dictionary\n",
    "            di_tilde = min(len(V)-1, max(1, d[vi] + dlaplace.rvs(2/epsilon)))    ## 19\n",
    "            ## should probably be len(V)-1 since we cannot connect to self\n",
    "            d[vi] = di_tilde## 20\n",
    "\n",
    "    ## laplaces = dlaplace.rvs(2/epsilon, size = len(d))\n",
    "    ## di_tilde = {d.keys(i): min(len(V), max(1, d[d.keys(i)] + laplaces[i])) for i in len(d)}\n",
    "\n",
    "    ##print(\"candidates and noise: \", time.time()-starttime)\n",
    "    ##starttime = time.time()\n",
    "    \n",
    "    while len(V) > 0:       ## 23, 45\n",
    "        ## 24: // Mechanism for preferentially selecting a node\n",
    "        ## 25: sample vi in V with prob di/sum(dk, k in V)\n",
    "        prob = [d[vi] for vi in V]   ## 25\n",
    "        vi = random.choices(population=V, weights=prob)[0]      ## 25\n",
    "\n",
    "        if len(candidates[vi]) != 0: ## 26, 35      ## if vi has potential connections\n",
    "            ## 27: // Mechanism for preferentially generating an edge\n",
    "            ## 28: sample vj in vi_candidate with prob p(eij|vi) = F(i,j)/sum(F(i,k), for k in vi_candidates)\n",
    "            sumFik = sum([F[vi][k] for k in candidates[vi]]) ## 28\n",
    "            ## this sum is unneccessary if we make F an array, can use F[vi] directly\n",
    "            prob = [F[vi][vj]/sumFik for vj in candidates[vi]]  ## 28\n",
    "            vj = random.choices(population=candidates[vi], weights=prob)[0]   ## 28\n",
    "            candidates[vi].remove(vj)   ## 29\n",
    "            candidates[vj].remove(vi)   ## 29\n",
    "            if ((vi, vj) not in E_T) and ((vj,vi) not in E_T):  ## 30, 32   ## add the edge if it doesnt exist yet\n",
    "                E_T.append((vi,vj)) ## 31\n",
    "                d[vi] -= 1          ## 31\n",
    "                d[vj] -= 1          ## 31\n",
    "            if d[vj] == 0:   ## 39      ## remove vj from V if vj has no potential connections left (this is in here bc we do this only if vj has been selected this round)\n",
    "                V.remove(vj)\n",
    "        else:   ## 33, 35               ## if there are no candidates for vi, add to q\n",
    "            queue.append(vi)\n",
    "\n",
    "        if d[vi] == 0:   ## 36          ## remove vi from V if vi has no potential connections left\n",
    "            V.remove(vi)\n",
    "        if set(queue + V) == set(queue):    ## 41\n",
    "            break   ## exit the while loop if all vertices in V are already in the queue\n",
    "    ## 45: end while\n",
    "    ##print(\"buildQueue: \", time.time()-starttime)\n",
    "    ##starttime = time.time()\n",
    "\n",
    "    while len(queue) > 0:       ## 46\n",
    "        vi = random.choice(queue)         ## 47   ## selection method is uniform at random\n",
    "        queue.remove(vi)    ## we have now addressed this elm. and all other bits are done from V (not mentioned in pseudocode, implied by naming of queue)\n",
    "\n",
    "        ## generate list of unused pot. edges -> check for all potential edges if they have been used\n",
    "        potential_vj = [v for v in V if v!=vi]\n",
    "        for vj in potential_vj:     \n",
    "            if (vi,vj) in E_T or (vj,vi) in E_T:\n",
    "                potential_vj.remove(vj)\n",
    "\n",
    "        if len(potential_vj) > 0:            ## 48: if V not empty   ## pseudocode would run forever if all pot. edges used up\n",
    "            workingV = V\n",
    "            sumDegk = np.sum([d[k] for k in V])\n",
    "            prob = [d[vj]/sumDegk for vj in V]\n",
    "            vj = random.choices(population=V, weights= prob)[0]     ## 50\n",
    "            if vj == vi or (vi,vj) in E_T or (vj,vi) in E_T:     ## 49,51    ## wait until none of these are true\n",
    "                workingV.remove(vj)\n",
    "                sumDegk = np.sum([d[k] for k in workingV])\n",
    "                prob = [d[vj]/sumDegk for vj in workingV]\n",
    "                vj = random.choices(population=workingV, weights= prob)[0] ## 50\n",
    "            d[vj] -= 1          ## 52\n",
    "            E_T.append((vi,vj)) ## 52\n",
    "            if d[vj] == 0:   ## 53, 55\n",
    "                V.remove(vj)    ## 54\n",
    "        else:   ## if V empty / if there are no possible edges for vi\n",
    "            if vi in V: ## else we dont have to bc its already gone\n",
    "                V.remove(vi)    ## remove it from nodeslist\n",
    "\n",
    "    ##print(time.time()-starttime)\n",
    "    \n",
    "    ## 58: return E_T\n",
    "    anonG = nx.Graph()\n",
    "    anonG.add_nodes_from(G.nodes())\n",
    "    anonG.add_edges_from(E_T)\n",
    "    return anonG    ## this algorithm returns an anonymized graph rather than an edgelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "and running on the 10k graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## import the graph\n",
    "HBA_10k_82 = nx.read_gml(\"../Data/HBA/HBA_10k_82.gml\", destringizer=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60.96078014373779\n",
      "672.9750831127167\n"
     ]
    }
   ],
   "source": [
    "## run the anonymisation on the graph\n",
    "HBA_10k_82_anon = DP_FT(HBA_10k_82)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export the new graph\n",
    "nx.write_adjlist(HBA_10k_82_anon, \"../anonymisedGraphs/HBA_10k_82_DPFT_14-06\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:14:05.059928\n",
      "0:14:43.701985\n",
      "0:15:38.251593\n",
      "0:14:52.794308\n",
      "0:11:41.730999\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    start = datetime.datetime.now()\n",
    "    HBA_10k_82_anon = DP_FT(HBA_10k_82)\n",
    "    nx.write_adjlist(HBA_10k_82_anon, \"../anonymisedGraphs/HBA_10k_82_DPFT_29-06_v\"+str(i))\n",
    "    print(datetime.datetime.now() - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
