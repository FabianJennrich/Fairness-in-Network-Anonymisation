{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PBCN approach\n",
    "\n",
    "- releases a noisy graph, uses a privacy protection measure alg based on adjacency degree\n",
    "- method has 5 algs\n",
    "    1) clustering based on node degree\n",
    "        - group the degree sequence, and get the avg deg of each cluster\n",
    "    2) random disturbance based on groups\n",
    "        - disturb the groups, and update the centers and stuff accordingly\n",
    "    3) noise addition (laplace)\n",
    "        - for each node, add noise to the degree\n",
    "    4) graph reconstruction (Havel thm)\n",
    "        - takes perturbed deg sequence as input\n",
    "    5) post processing\n",
    "- are node communities identifyable in finished graph\n",
    "    - seems that we perturb a degree sequence, so if we keep the node names as we go, this should be fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "import random\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.stats import dlaplace, binom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we use the DD199 graph for testing\n",
    "import pandas as pd\n",
    "DD199 = nx.read_edgelist(\"Data/DD199/DD199.edges\", nodetype=int)\n",
    "\n",
    "BAG = nx.barabasi_albert_graph(20,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def groupConstruction(degSeq, T):\n",
    "    '''\n",
    "    Algorithm 1: ... based on K-means clustering\n",
    "    Outputs dictionaries of clustering centers  C= clusterID: clusterCenter, groupNodes = nodeID: groupID, D = groupID:[nodes]\n",
    "    '''\n",
    "    ## dist(u,v) = |d(u) - d(v)|\n",
    "    ## we assume degSeq is degree dictionary\n",
    "    degSeqNodes = list(degSeq.keys())\n",
    "    degSeqArr = np.array(list(degSeq.values())).reshape(-1,1)  ## create an array of degs while maintaining ordering\n",
    "    mymeans = KMeans(n_clusters=T).fit(degSeqArr)\n",
    "\n",
    "    unsortedC = {i: mymeans.cluster_centers_[i] for i in range(T)}  ## clusterID : cluster mean         clusterIDs are just 0-num clusters\n",
    "    sortedClusterIDs = sorted(unsortedC, key= unsortedC.get, reverse=True)  ## clusterIDs by descending cluster mean\n",
    "    ## oldID : newID \n",
    "    toNewID = {sortedClusterIDs[newid]: newid for newid in range(len(sortedClusterIDs))}        ## oldID: newID\n",
    "\n",
    "    C = {toNewID[oldID]: mymeans.cluster_centers_[oldID] for oldID in range(T)}\n",
    "    nodeGroups = {degSeqNodes[i] : toNewID[mymeans.labels_[i]] for i in range(len(degSeqNodes))}          ## node: Old->New (old clusterID)\n",
    "    D = {}\n",
    "    for node in nodeGroups:\n",
    "        if nodeGroups[node] in D:\n",
    "            D[nodeGroups[node]].append(node)\n",
    "        else:\n",
    "            D[nodeGroups[node]] = [node]\n",
    "\n",
    "    ## we want C[i] >= C[i+1] for all i, so we want to rename the clusters by their means\n",
    "\n",
    "    return C, nodeGroups, D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomDisturbance (G:nx.Graph, K, epsilon_1, nodeGroup, D):\n",
    "    '''\n",
    "    Algorithm 2: ... based on groups for pre-processing\n",
    "    Returns reconstruction graph G'\n",
    "    K is number of changed edges, nodeGroup is node: groupID, D is groupID : [nodes]\n",
    "    '''\n",
    "    T = len(D)\n",
    "    Gprime = G.copy()\n",
    "    epsilon_once = epsilon_1 / K\n",
    "    for i in range(K):      ## do K times                                   ## 2\n",
    "        (x,y) = random.choice(list(Gprime.edges()))                         ## a\n",
    "        ## nodeGroup[x] nodeGroup[y] is i and j respectively\n",
    "        ## Laplace noise eta_1 and eta_2 with 1/epsilon_once\n",
    "        eta_1, eta_2 = dlaplace.rvs(1/epsilon_once, loc = 0, size = 2)   ## b\n",
    "        iprime = (nodeGroup[x] + eta_1)%T\n",
    "        jprime = (nodeGroup[y] + eta_2)%T       ## we use mod T so that we dont get overspill\n",
    "        xprime = random.choice(D[iprime])       ## choose random nodes from new groups\n",
    "        yprime = random.choice(D[jprime])\n",
    "        if (xprime, yprime) not in Gprime.edges():\n",
    "            Gprime.remove_edge(x, y)\n",
    "            Gprime.add_edge(xprime,yprime)\n",
    "\n",
    "    return Gprime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "def noiseAllocation(Gprime:nx.Graph, D, C, epsilon_2):\n",
    "    '''\n",
    "    Algorithm 3: ... based on Laplace mechanism\n",
    "    Returns noisy degree sequecne node: degree\n",
    "    '''\n",
    "    d = dict(Gprime.degree())\n",
    "    m = Gprime.number_of_edges()\n",
    "\n",
    "    Dprime = {i:[] for i in D}   ## same length as D, and all els = 0 ## use empty list so that it doesnt get fucked\n",
    "\n",
    "    ## sensitivity S(f)_L(i) of f for ith group = Sf * sum Di / (2m) \n",
    "    Sf = {i: 2 * C[i]* len(D[i]) / m for i in C}       ## Sf = 4, C[i]*len(D[i]) = sum of Di degrees approx since we did perturbation\n",
    "    \n",
    "    ## laplace noise eta_3 from Lap(S(f)_L(i) / epsilon_2)\n",
    "    ## randomly distribtue noise ?  -> add noise?\n",
    "    for i in C:     ## iterate through groupIDs\n",
    "        Dinoise = dlaplace.rvs(Sf[i]/epsilon_2, loc=0, size = len(D[i]))\n",
    "        ## for each node, we want to add noise\n",
    "        Dprime[i] = [d[D[i][j]] + Dinoise[j] for j in range(len(D[i]))]\n",
    "    ## the paper was unclear, so I have chosen to do this as in differentialPrivacy.ipynb\n",
    "\n",
    "    dnoised = {D[i][j]: Dprime[i][j] for i in D for j in range(len(D[i]))}   ## node: \n",
    "    return dnoised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildNoiseEdge(Gprime:nx.Graph, noisedDegSeq):\n",
    "    '''\n",
    "    Algorithm 4: ... according to Havel Thm\n",
    "    Returns reconstructed graph G'' (we call it Ganon for ease of reading)\n",
    "    Takes G' (original graph with K changed edges), and noised degree sequence Dprime\n",
    "    for (-) entries in Dprime, delete the edges constructed by Havel Theorem\n",
    "    for (+) entries add edges constructed by Havel theorem\n",
    "    NOTE: does not check if the degree sequences are graphical, makes them even by just adding 1 to deg of vertex 0, \n",
    "    if otherwise ungraphical just throws an error\n",
    "    '''\n",
    "    Ganon = Gprime.copy()\n",
    "    ## we need an even sum of degrees to construct the degree sequence\n",
    "    ## connect node of highest degree to other nodes of highest degree\n",
    "    ## actually split into (+) and (-) parts, pass to havel_graph or whatever\n",
    "    ## then add / remove edges\n",
    "    Da = []\n",
    "    Db = []\n",
    "    Damap = {}\n",
    "    Dbmap = {}\n",
    "    for i in Gprime.nodes():    ## we trust that these are in order 0-n     ## if they are not, there will be issues in Havel graphs\n",
    "        if noisedDegSeq[i] >= 0:\n",
    "            Damap[len(Da)] = i\n",
    "            Da.append(noisedDegSeq[i])\n",
    "        else:   ## if < 0 i.e. (-)\n",
    "            Dbmap[len(Db)] = i\n",
    "            Db.append(-1*noisedDegSeq[i])\n",
    "    if sum(Da) %2 ==1:\n",
    "        Da[0] += 1\n",
    "    if sum(Db) %2 ==1:\n",
    "        Db[0] += 1\n",
    "    DaHH = nx.havel_hakimi_graph(Da)\n",
    "    DaHH = nx.relabel_nodes(DaHH, Damap, copy=False)\n",
    "    DbHH = nx.havel_hakimi_graph(Db)\n",
    "    DbHH = nx.relabel_nodes(DbHH, Dbmap, copy=False)        ## constructed edges based on havel thm, with intact node names\n",
    "\n",
    "    Ganon.add_edges_from(DaHH.edges())\n",
    "    for edge in DbHH.edges():\n",
    "        if edge in Ganon.edges():\n",
    "            Ganon.remove_edge(*edge)\n",
    "\n",
    "    return Ganon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postProcessing (Ganon:nx.Graph, epsilon_3):\n",
    "    '''\n",
    "    Algorithm 5: ... by adding node noises\n",
    "    Returns reconstructed graph G'\n",
    "    '''\n",
    "    GanonPP = Ganon.copy()\n",
    "    n = Ganon.number_of_nodes()\n",
    "    d = [val for (_, val) in Ganon.degree()]\n",
    "    d_noise = np.quantile(d, 0.05)  ## smallest 5% of nodes\n",
    "\n",
    "    eta_4 = dlaplace.rvs(1/epsilon_3, loc=0, size = 1)[0]\n",
    "    if eta_4 <0:\n",
    "        smallDegs = [i for i in Ganon.nodes() if Ganon.degree(i) <= d_noise]\n",
    "        if len(smallDegs) >= eta_4*-1:\n",
    "            nodesToRemove = random.choices(smallDegs, k= eta_4*-1)\n",
    "            GanonPP.remove_nodes_from(nodesToRemove)\n",
    "        else:\n",
    "            GanonPP.remove_nodes_from(smallDegs)\n",
    "    if eta_4 >0:\n",
    "        for i in range(eta_4):\n",
    "            R = binom.rvs(n, p=d_noise/n, size = 1)[0] ## how many nodes to connect to\n",
    "            nodesToConnect = random.choices(list(GanonPP.nodes()), k=R)\n",
    "            edgesToAdd = [(n+i, node) for node in nodesToConnect]\n",
    "            GanonPP.add_node(n+i)\n",
    "            GanonPP.add_edges_from(edgesToAdd)\n",
    "    return GanonPP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PBCNanonymisation(G:nx.Graph):\n",
    "    '''Produces anonymised graph\n",
    "    T number of groups, K number of noise edges, epsilon privacy budget\n",
    "    smaller epsilon the more edges are added -> longer run time\n",
    "    '''\n",
    "    epsilon=0.1\n",
    "    K = int(G.number_of_edges()/100)+1\n",
    "    T=10\n",
    "\n",
    "    degSeq = dict(G.degree())\n",
    "    C, groupNodes, D = groupConstruction(degSeq=degSeq, T=T)\n",
    "    Gprime = randomDisturbance(G, K, epsilon_1=epsilon/3, nodeGroup=groupNodes, D=D)\n",
    "    degSeqNoised = noiseAllocation(Gprime, D, C, epsilon/3)\n",
    "    Ganon = buildNoiseEdge(Gprime, degSeqNoised)\n",
    "    Ganon = postProcessing(Ganon, epsilon/3)    ## d_noise is smallest 5% of degrees\n",
    "    return Ganon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
